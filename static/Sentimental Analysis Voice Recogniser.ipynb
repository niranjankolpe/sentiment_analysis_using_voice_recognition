{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e5091c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "import re,joblib\n",
    "import speech_recognition as sr\n",
    "import datetime\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13ec4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audioInput():\n",
    "    engine = pyttsx3.init('sapi5')\n",
    "    voice = engine.getProperty('voices')\n",
    "    engine.setProperty('voices', voice[1].id)\n",
    "    \n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        engine.say(\"Hello! Say anything I am listening...\")\n",
    "        print(\"Hello! Say anything I am listening...\")\n",
    "        engine.runAndWait()\n",
    "        \n",
    "        r.adjust_for_ambient_noise(source, duration = 1)\n",
    "        try:\n",
    "            audio = r.listen(source)\n",
    "            text = r.recognize_google(audio, language='en')\n",
    "            text = text.lower()\n",
    "            print(\"You said: {0}\".format(text))\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            engine.say(\"Could not hear you, try again!\")\n",
    "            print(\"Could not hear you, try again!\")\n",
    "            return False\n",
    "        except sr.RequestError:\n",
    "            engine.say(\"Make sure you have a good internet!\")\n",
    "            print(\"Make sure you have a good internet!\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d04d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_transformation(df_col):\n",
    "    corpus = list()\n",
    "    for item in df_col:\n",
    "        new_item = re.sub('[^a-zA-Z]', ' ', str(item))\n",
    "        new_item = new_item.lower()\n",
    "        new_item = new_item.split()\n",
    "        new_item = [lm.lemmatize(word) for word in new_item if word not in set(stopwords.words('english'))]\n",
    "        corpus.append(' '.join(str(x) for x in new_item))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5a7f1ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer()\n",
    "cv = joblib.load('joblib_count_vector_model')\n",
    "# rf = joblib.load('joblib_sentimental_model')\n",
    "rf = open(\"joblib_sentimental_model\", \"rb\")\n",
    "rf = rf.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f52f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expressin_check(prediction_input):\n",
    "    if prediction_input==0:\n",
    "        speak(\"Input statement has negative sentiment\")\n",
    "        return \"Negative\"\n",
    "    elif prediction_input==1:\n",
    "        speak(\"Input statement has positive sentiment\")\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        speak(\"Invalid statement\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "181d1f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predictor(input):\n",
    "    corpus = text_transformation(query)\n",
    "    transformed_input = cv.transform(corpus)\n",
    "    prediction = rf.predict(transformed_input)\n",
    "    sentiment_result = expressin_check(prediction)\n",
    "    return sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fee4f6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Say anything I am listening...\n",
      "Could not hear you, try again!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m audioInput()\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msentiment_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[59], line 2\u001b[0m, in \u001b[0;36msentiment_predictor\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentiment_predictor\u001b[39m(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     corpus \u001b[38;5;241m=\u001b[39m \u001b[43mtext_transformation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     transformed_input \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mtransform(corpus)\n\u001b[0;32m      4\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(transformed_input)\n",
      "Cell \u001b[1;32mIn[56], line 3\u001b[0m, in \u001b[0;36mtext_transformation\u001b[1;34m(df_col)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext_transformation\u001b[39m(df_col):\n\u001b[0;32m      2\u001b[0m     corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m df_col:\n\u001b[0;32m      4\u001b[0m         new_item \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[^a-zA-Z]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(item))\n\u001b[0;32m      5\u001b[0m         new_item \u001b[38;5;241m=\u001b[39m new_item\u001b[38;5;241m.\u001b[39mlower()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'bool' object is not iterable"
     ]
    }
   ],
   "source": [
    "query = audioInput()\n",
    "result = sentiment_predictor(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1298d6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey how are you'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80a08001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'e', '', '', 'h', '', 'w', '', '', 'r', 'e', '', '', '', 'u']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b50e17f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15x117594 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faf91dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11d15c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listening...\n",
      "recognizing...\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'query' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m questions:\n\u001b[0;32m      4\u001b[0m     speak(question\u001b[38;5;241m.\u001b[39mlower())\n\u001b[1;32m----> 5\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[43mtakecommand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m      6\u001b[0m     sentiment_predictor([query])\n",
      "Cell \u001b[1;32mIn[11], line 18\u001b[0m, in \u001b[0;36mtakecommand\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mRequestError:\n\u001b[0;32m     16\u001b[0m     speak(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmake sure you have a goog internet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery\u001b[49m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'query' referenced before assignment"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    wishme()\n",
    "    for question in questions:\n",
    "        speak(question.lower())\n",
    "        query = takecommand().lower()\n",
    "        sentiment_predictor([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0f921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030e465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2f0c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb3272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e95bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86757773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b57cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 86\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m questions:\n\u001b[0;32m     85\u001b[0m     speak(question\u001b[38;5;241m.\u001b[39mlower())\n\u001b[1;32m---> 86\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[43mtakecommand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m     87\u001b[0m     sentiment_predictor([query])\n",
      "Cell \u001b[1;32mIn[1], line 69\u001b[0m, in \u001b[0;36mtakecommand\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlistening...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     68\u001b[0m     speak(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlistening\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecognizing...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\speech_recognition\\__init__.py:523\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    525\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pyttsx3\n",
    "import re,joblib\n",
    "import speech_recognition as sr\n",
    "import datetime,nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "engine =pyttsx3.init('sapi5')\n",
    "voice = engine.getProperty('voices')\n",
    "engine.setProperty('voices',voice[1].id)\n",
    "\n",
    "questions  = [\n",
    "    'how are you?',\n",
    "    'do you like icecream',\n",
    "]\n",
    "\n",
    "lm = WordNetLemmatizer()\n",
    "cv = joblib.load('joblib_count_vector_model')\n",
    "# rf = joblib.load('joblib_sentimental_model')\n",
    "rf = open(\"joblib_sentimental_model\", \"rb\")\n",
    "rf.read()\n",
    "\n",
    "def text_transformation(df_col):\n",
    "    corpus=[]\n",
    "    for item in df_col:\n",
    "        new_item=re.sub('[^a-zA-Z]',' ',str(item))\n",
    "        new_item=new_item.lower()\n",
    "        new_item=new_item.split()\n",
    "        new_item=[lm.lemmatize(word)for word in new_item if word not in set(stopwords.words('english'))]\n",
    "        corpus.append(' '.join(str(x)for x in new_item))\n",
    "    return corpus\n",
    "\n",
    "def expressin_check(prediction_input):\n",
    "    if prediction_input==0:\n",
    "        speak(\"Input statement has negative sentiment\")\n",
    "    elif prediction_input==1:\n",
    "        speak(\"Input statement has positive sentiment\")\n",
    "    else:\n",
    "        speak(\"invalid statement\")\n",
    "\n",
    "def sentiment_predictor(input):\n",
    "    input=text_transformation(input)\n",
    "    transformed_input=cv.transform(input)\n",
    "    prediction=rf.predict(transformed_input)\n",
    "    print(prediction)\n",
    "    expressin_check(prediction)\n",
    "\n",
    "def wishme():\n",
    "    hour = int(datetime.datetime.now().hour)\n",
    "    if hour >=0 and hour < 12:\n",
    "        speak(\"good morning master\")\n",
    "    elif hour >=12 and hour <18:\n",
    "        speak(\"good afternoon master\")\n",
    "    else:\n",
    "        speak('good evening master')\n",
    "\n",
    "def speak(audio):\n",
    "    engine.say(audio)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def takecommand():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        r.adjust_for_ambient_noise(source,1)\n",
    "        print('listening...')\n",
    "        speak('listening')\n",
    "        audio = r.listen(source)\n",
    "    try:\n",
    "        print('recognizing...')\n",
    "        speak('analyzing the statement')\n",
    "        query = r.recognize_google(audio,language='en')\n",
    "        print(f'User said {query}')\n",
    "    except sr.UnknownValueError:\n",
    "        speak('could not hear you, try again')\n",
    "    except sr.RequestError:\n",
    "        speak('make sure you have a goog internet')\n",
    "    \n",
    "    return query\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    wishme()\n",
    "    for question in questions:\n",
    "        speak(question.lower())\n",
    "        query = takecommand().lower()\n",
    "        sentiment_predictor([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5aa5eb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m lm \u001b[38;5;241m=\u001b[39m WordNetLemmatizer()\n\u001b[0;32m     20\u001b[0m cv \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjoblib_count_vector_model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m rf \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjoblib_sentimental_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext_transformation\u001b[39m(df_col):\n\u001b[0;32m     24\u001b[0m     corpus\u001b[38;5;241m=\u001b[39m[]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py:587\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    582\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    583\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    584\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    585\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 587\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py:506\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    504\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 506\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[0;32m    508\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    509\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    511\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[0;32m    512\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1213\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import pyttsx3\n",
    "import re,joblib\n",
    "import speech_recognition as sr\n",
    "import datetime,nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "engine =pyttsx3.init('sapi5')\n",
    "voice = engine.getProperty('voices')\n",
    "engine.setProperty('voices',voice[1].id)\n",
    "\n",
    "questions  = [\n",
    "    'how are you?',\n",
    "    'do you like icecream',\n",
    "]\n",
    "\n",
    "lm = WordNetLemmatizer()\n",
    "cv = joblib.load('joblib_count_vector_model')\n",
    "rf = joblib.load('joblib_sentimental_model')\n",
    "\n",
    "def text_transformation(df_col):\n",
    "    corpus=[]\n",
    "    for item in df_col:\n",
    "        new_item=re.sub('[^a-zA-Z]',' ',str(item))\n",
    "        new_item=new_item.lower()\n",
    "        new_item=new_item.split()\n",
    "        new_item=[lm.lemmatize(word)for word in new_item if word not in set(stopwords.words('english'))]\n",
    "        corpus.append(' '.join(str(x)for x in new_item))\n",
    "    return corpus\n",
    "\n",
    "def expressin_check(prediction_input):\n",
    "    if prediction_input==0:\n",
    "        speak(\"Input statement has negative sentiment\")\n",
    "    elif prediction_input==1:\n",
    "        speak(\"Input statement has positive sentiment\")\n",
    "    else:\n",
    "        speak(\"invalid statement\")\n",
    "\n",
    "def sentiment_predictor(input):\n",
    "    input=text_transformation(input)\n",
    "    transformed_input=cv.transform(input)\n",
    "    prediction=rf.predict(transformed_input)\n",
    "    print(prediction)\n",
    "    expressin_check(prediction)\n",
    "\n",
    "def wishme():\n",
    "    hour = int(datetime.datetime.now().hour)\n",
    "    if hour >=0 and hour < 12:\n",
    "        speak(\"good morning master\")\n",
    "    elif hour >=12 and hour <18:\n",
    "        speak(\"good afternoon master\")\n",
    "    else:\n",
    "        speak('good evening master')\n",
    "\n",
    "def speak(audio):\n",
    "    engine.say(audio)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def takecommand():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        r.adjust_for_ambient_noise(source,1)\n",
    "        print('listening...')\n",
    "        speak('listening')\n",
    "        audio = r.listen(source)\n",
    "    try:\n",
    "        print('recognizing...')\n",
    "        speak('analyzing the statement')\n",
    "        query = r.recognize_google(audio,language='en')\n",
    "        print(f'User said {query}')\n",
    "    except sr.UnknownValueError:\n",
    "        speak('could not hear you, try again')\n",
    "    except sr.RequestError:\n",
    "        speak('make sure you have a goog internet')\n",
    "    \n",
    "    return query\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    wishme()\n",
    "    for question in questions:\n",
    "        speak(question.lower())\n",
    "        query = takecommand().lower()\n",
    "        sentiment_predictor([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1883f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
